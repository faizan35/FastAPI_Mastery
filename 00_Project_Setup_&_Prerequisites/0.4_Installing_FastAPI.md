# 0.4 Installing FastAPI with Uvicorn (default) & Uvicorn + Gunicorn (combined)

## **1. Installing FastAPI & Web Servers**

### **Installing FastAPI and Dependencies**

FastAPI requires Python **3.7+**, so ensure you have it installed:

```bash
python --version
```

If you don‚Äôt have it, install Python from [python.org](https://www.python.org/downloads/).

Now, install **FastAPI**:

```bash
pip install fastapi
```

This installs the **FastAPI framework** and its dependencies.

---

### **Installing Uvicorn (ASGI Server for FastAPI)**

FastAPI requires an **ASGI** server to run. The default choice is **Uvicorn**.

```bash
pip install uvicorn
```

To verify the installation:

```bash
uvicorn --version
```

**Now, FastAPI and Uvicorn are installed!**

---

### **Installing Gunicorn (Optional, for Production)**

Gunicorn is used for **process management** in production. To install it:

```bash
pip install gunicorn
```

To check the installation:

```bash
gunicorn --version
```

**Now, Gunicorn is installed and ready for production use!**

---

## **2. Setting Up a Simple FastAPI App**

### **Creating a FastAPI Project Structure**

Create a new project folder and navigate to it:

```bash
mkdir fastapi_project && cd fastapi_project
```

Inside this folder, create a new Python file:

```bash
touch main.py
```

Now, your structure should look like:

```
fastapi_project/
‚îÇ‚îÄ‚îÄ main.py
```

---

### **Writing a Basic FastAPI App**

Open `main.py` and add this simple FastAPI app:

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
async def home():
    return {"message": "Hello, FastAPI!"}
```

This defines:

- A **FastAPI instance** (`app`).
- A **GET endpoint** (`/`) that returns a JSON response.

---

### **Running the App with Uvicorn**

Start the FastAPI app using Uvicorn:

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

**Explanation:**

- `main:app` ‚Üí `module_name:FastAPI_instance` (Here, `main.py` contains `app`).
- `--host 0.0.0.0` ‚Üí Makes the app accessible on the network.
- `--port 8000` ‚Üí Runs the app on **port 8000**.
- `--reload` ‚Üí Enables **auto-reloading** (useful for development).

---

### **Testing the FastAPI App**

After running the above command, open your browser and go to:

- **FastAPI Homepage:** [http://127.0.0.1:8000](http://127.0.0.1:8000)
- **FastAPI Interactive Docs (Swagger UI):** [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **Alternative Docs (ReDoc):** [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

**You should see:**

```json
{ "message": "Hello, FastAPI!" }
```

üéâ **Congratulations! You've successfully installed FastAPI and run your first app!** üöÄ

---

## **3. Running FastAPI with Uvicorn (Default Setup)**

Now that we have installed FastAPI and written a basic app, let's explore how to run it efficiently using **Uvicorn**.

### **1. Starting the FastAPI App with Uvicorn**

If you have not already, ensure you are inside your project folder where `main.py` exists.

#### **Basic Command to Run FastAPI with Uvicorn**

```bash
uvicorn main:app
```

This will start the server with **default settings**:

- **Host:** `127.0.0.1` (localhost)
- **Port:** `8000`
- **Single worker**
- **No automatic reloading**

Open [http://127.0.0.1:8000](http://127.0.0.1:8000) in your browser to test it.

---

### **2. Configuring Host, Port, and Reload Options**

#### **Running FastAPI on a Specific Host and Port**

```bash
uvicorn main:app --host 0.0.0.0 --port 8080
```

This makes the API accessible on the **network** (`0.0.0.0`) and changes the port to **8080**.

#### **Enabling Auto-Reload (for Development Mode)**

During development, it's useful to **auto-restart the server** when code changes.

```bash
uvicorn main:app --reload
```

**Why use `--reload`?**

- It detects code changes and **automatically restarts the server**.
- Useful for **development**, but should be **avoided in production**.

#### **Combining All Options Together**

```bash
uvicorn main:app --host 0.0.0.0 --port 8080 --reload
```

**Best for development!** üöÄ

---

### **3. Running FastAPI with Multiple Workers**

By default, Uvicorn runs in **a single process**. To handle **more concurrent requests**, we can run it with **multiple worker processes**.

#### **Running with 4 Workers**

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

**Why use multiple workers?**

- Each worker runs **independently** and can handle requests in parallel.
- Useful for **CPU-bound** tasks (like machine learning, image processing).
- Helps in **scalability** and improves API **throughput**.

‚ö†Ô∏è **Important:**

- `--workers` works **only** when running **without `--reload`**.
- In **development**, **use `--reload`** (single worker).
- In **production**, use **multiple workers**.

---

### **Final Summary**

| Command                                       | Purpose                                                   |
| --------------------------------------------- | --------------------------------------------------------- |
| `uvicorn main:app`                            | Run FastAPI with default settings.                        |
| `uvicorn main:app --host 0.0.0.0 --port 8000` | Run on a specific host and port.                          |
| `uvicorn main:app --reload`                   | Enable **auto-reloading** (development mode).             |
| `uvicorn main:app --workers 4`                | Run FastAPI with **4 worker processes** (for production). |

---

## **4. Running FastAPI with Gunicorn + Uvicorn (Production Setup)**

FastAPI can run directly with Uvicorn, but for production environments, it is recommended to use **Gunicorn** as a process manager along with Uvicorn workers. Gunicorn helps manage multiple processes, handle worker restarts, and distribute requests efficiently.

---

### **1. Installing Gunicorn**

If you haven't installed Gunicorn yet, install it using pip:

```bash
pip install gunicorn
```

To verify the installation:

```bash
gunicorn --version
```

---

### **2. Running FastAPI with Gunicorn and Uvicorn Workers**

Gunicorn does not support ASGI applications directly, so it requires **Uvicorn workers** to serve FastAPI.

#### **Basic Command to Run FastAPI with Gunicorn + Uvicorn**

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000 main:app
```

**Explanation:**

- `-w 4` ‚Üí Uses **4 worker processes**.
- `-k uvicorn.workers.UvicornWorker` ‚Üí Uses **Uvicorn as the worker**.
- `-b 0.0.0.0:8000` ‚Üí Binds the server to port **8000**.
- `main:app` ‚Üí `main.py` contains the FastAPI instance named `app`.

This setup provides **better performance and process management** compared to running Uvicorn alone.

---

### **3. Configuring Worker Count and Process Management**

The number of **workers** should be based on the number of CPU cores available on the machine. A common formula for setting the number of workers:

```bash
workers = (2 x CPU cores) + 1
```

To determine the number of CPU cores:

```bash
python -c "import multiprocessing; print(multiprocessing.cpu_count())"
```

For example, if the system has **4 CPU cores**, the recommended number of workers would be:

```bash
gunicorn -w 9 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000 main:app
```

To optimize process management, consider adding:

- `--timeout 120` ‚Üí Set worker timeout to 120 seconds.
- `--log-level info` ‚Üí Set logging level.
- `--access-logfile gunicorn_access.log` ‚Üí Log all requests to a file.

Example:

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000 main:app --timeout 120 --log-level info --access-logfile gunicorn_access.log
```

---

### **When to Use Gunicorn + Uvicorn**

- When deploying **FastAPI in production**.
- When running **multiple processes** for better concurrency.
- When needing **process supervision and worker management**.
- When running behind a **load balancer** (e.g., Nginx, Traefik).

---

## **5. Performance Considerations & Best Practices**

### **1. Choosing the Right Number of Workers**

The number of **workers** determines how many processes will handle incoming requests. Too few workers can result in slow request handling, while too many can exhaust system resources.

A commonly used formula for worker calculation:

```bash
workers = (2 x CPU cores) + 1
```

To check the number of CPU cores:

```bash
python -c "import multiprocessing; print(multiprocessing.cpu_count())"
```

For example, if the system has **4 CPU cores**, the recommended number of workers is:

```bash
gunicorn -w 9 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000 main:app
```

**Best Practices:**

- For **I/O-bound applications** (database-heavy, API calls): Use **more workers**.
- For **CPU-bound applications** (machine learning, video processing): Use **fewer workers** with **async operations**.

---

### **2. When to Use Uvicorn Alone vs. Gunicorn + Uvicorn**

| Scenario                                    | Use Uvicorn | Use Gunicorn + Uvicorn |
| ------------------------------------------- | ----------- | ---------------------- |
| **Development**                             | ‚úÖ Yes      | ‚ùå No                  |
| **Small-scale applications**                | ‚úÖ Yes      | ‚ùå No                  |
| **Production deployment**                   | ‚ùå No       | ‚úÖ Yes                 |
| **High concurrency needed**                 | ‚ùå No       | ‚úÖ Yes                 |
| **Process supervision & auto-restart**      | ‚ùå No       | ‚úÖ Yes                 |
| **Behind a load balancer (Nginx, Traefik)** | ‚ùå No       | ‚úÖ Yes                 |

Use **Uvicorn alone** when:

- Running locally for **development and testing**.
- Deploying a lightweight API with **low traffic**.

Use **Gunicorn + Uvicorn** when:

- Running in **production**.
- Handling **high concurrency**.
- Requiring **worker process management**.

---

### **3. Deployment Optimizations**

#### **1. Enable Keep-Alive**

Allow persistent connections to reduce overhead:

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker --keep-alive 5 -b 0.0.0.0:8000 main:app
```

#### **2. Optimize Worker Class**

- **For async applications** ‚Üí Use `uvicorn.workers.UvicornWorker`.
- **For CPU-intensive tasks** ‚Üí Consider using `sync` workers.

#### **3. Set Worker Timeouts**

Prevent slow responses from blocking workers:

```bash
--timeout 120
```

#### **4. Use Load Balancers**

Deploy FastAPI behind **Nginx, Traefik, or AWS ALB** for scalability.

#### **5. Optimize Database Connections**

Use **async database connections** like **Tortoise ORM** or **SQLAlchemy 2.0 async engine**.

---

## **6. Deploying FastAPI with Docker (Bonus Section)**

### **1. Writing a Dockerfile for FastAPI**

Create a file named **`Dockerfile`** in your FastAPI project directory:

```dockerfile
# Use an official Python image
FROM python:3.10

# Set the working directory inside the container
WORKDIR /app

# Copy the application files
COPY . /app

# Install dependencies
RUN pip install --no-cache-dir fastapi uvicorn gunicorn

# Expose port 8000
EXPOSE 8000

# Run FastAPI with Uvicorn
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### **2. Running FastAPI with Uvicorn inside Docker**

#### **1. Build the Docker Image**

```bash
docker build -t fastapi-app .
```

#### **2. Run the Container**

```bash
docker run -p 8000:8000 fastapi-app
```

The application will be accessible at **http://localhost:8000**.

---

### **3. Running FastAPI with Gunicorn + Uvicorn inside Docker**

Modify the `Dockerfile` to run **Gunicorn + Uvicorn** for production:

```dockerfile
FROM python:3.10

WORKDIR /app

COPY . /app

RUN pip install --no-cache-dir fastapi uvicorn gunicorn

EXPOSE 8000

CMD ["gunicorn", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000", "main:app"]
```

#### **1. Build the Docker Image**

```bash
docker build -t fastapi-gunicorn .
```

#### **2. Run the Container**

```bash
docker run -p 8000:8000 fastapi-gunicorn
```

---

### **Final Thoughts**

- Use **Uvicorn** alone for **development**.
- Use **Gunicorn + Uvicorn** for **production**.
- Use **Docker** to **containerize FastAPI applications** for deployment.
